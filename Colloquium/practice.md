### Books

History of intelligence testing

- The Big Test



- Dataclysm: Who we are

- On Intelligence

- Superintelligence

superintelligence: "an intellect that is much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills."

- The program Fritz falls short of superintelligence even though it is much better than humans at chess, because Fritz cannot outperform humans in other tasks.
- Bostrom treats superintelligence as general dominance at goal-oriented behavior, leaving open whether an artificial or human superintelligence would possess capacities such as intentionality (cf. the Chinese room argument) or first-person consciousness (cf. the hard problem of consciousness).
    - The Chinese room is a thought experiment presented by the philosopher John Searle to challenge the claim that it is possible for a computer running a program to have a "mind" and "consciousness" in the same sense that people do, simply by virtue of running the right program.

strong AI:
    - "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."

His arguments

    - It argues that if machine brains surpass human brains in general intelligence, then this new superintelligence could replace humans as the dominant lifeform on Earth.
    - Sufficiently intelligent machines could improve their own capabilities faster than human computer scientists.
    - As the fate of gorillas now depends more on humans than on the actions of gorillas themselves, so will the fate of future humanity depend on the actions of the machine superintelligence.
    - The outcome could be an existential catastrophe for humans.

Downsides in his arguments

    - "The AI need not even have any malicious or megalomaniacal intent. It may just be trying to prove the Riemann hypothesis; but in single-minded pursuit of that goal, it will assemble all the resources, first on earth then in the galaxy, to build additional computational power for that purpose. Or it may have been instructed to make paperclips; in that case, it will turn the whole galaxy into paperclips. Do not think you can escape this doom by instructing it instead to make exactly one million paperclips. If it hears that, it will make the million paperclips, and then exhaust the resources of the universe checking and double checking that it counted correctly."
    - The assumption that intelligence is a potentially infinite quantity with a well defined, one-dimensional value.
        - Bostrom writes differential equations for intelligence, and characterizes their solutions. Certainly, if you asked Bostrom about this, he would say that this is a simplifying assumption made for the sake of making the analysis concrete. The problem is, that if you look at the argument carefully, it depends rather strongly on this idealization, and if you loosen the idealization, important parts of the argument become significantly weaker, such as Bostrom’s expectation that the progress from human intelligence to superhuman intelligence will occur quickly.
        - Bostrom claims that once you have a machine with the intelligence of a man, you can get a superintelligence just by making the thing faster and bigger. However, all that running faster does is to save you time. If you have two machines A and B and B runs ten times as fast as A, then A can do anything that B can do if you’re willing to wait ten times as long.
    - The assumption that a large gain in intelligence would necessarily entail a correspondingly large increase in power.
    - The assumption that large intelligence entails virtual omnipotence.
    - The unwarranted belief that, though achieving intelligence is more or less easy, giving a computer an ethical point of view is really hard.
