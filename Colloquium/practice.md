### Books

History of intelligence testing

- "In 1933, he became an assistant dean at Harvard University, where James Bryant Conant had just become president.

Conant was dissatisfied with the shallowness of undergraduate life at Harvard, where too many rich playboys came from preparatory schools well prepared for the essay-style college board examination but thereafter interested only in dancing, drinking, and fraternity high jinks.

Conant wanted to bring in good midwestern boys. However, they performed poorly on the examination, and the only means around it—admitting anyone in the top seventh of his class—only lured too many young men who quickly dropped out. Conant told Chauncey and his fellow dean, Wilbur Bender, to find a better method of winnowing the best candidates for admission"

- "Chauncey and Bender hastened to Princeton, where Carl Campbell Brigham had developed the SAT in 1926."
- "Brigham had initially believed that Nordics would always test higher than other groups, with mixed groups and African Americans scoring at the bottom. He worried greatly that American test scores were going down in the 1920’s. By 1928, however, he had changed his mind about the biological basis for IQ testing and was concentrating solely on the SAT’s predictive function in higher education."

- The Big Test

https://en.wikipedia.org/wiki/G_factor_(psychometrics)

The g factor is a construct developed in psychometric investigations of cognitive abilities and human intelligence.

- Dataclysm: Who we are

- A lot of the work that is done in this book concentrates on the idea of using data to make decisions and judgments. Really important to consider since most of the things that are being studied by AI (which we will go into later) is through recognitions of patterns in data.
- Similar to how we came to measure intelligence through intelligence testing: looking at patterns in the abilities an average person (which they create from perhaps a mean base score).
- This is a good book as it takes a dataset that exists in their data, and through several years makes predictions about social norms. The idea here is that these are some circumstances that are noticeable in their data.
- An example from the book: p106, p148 (political).
- Bring this up because it's important to consider the implications of this type of data. A lot of what we feed and learn from nowadays comes from a large plethora of this kind of data. Some of the claims made in this book come from Machine Learning algorithms or from algorithms that have learnt the data and made predictions on what it has meant.

- On Intelligence

- Superintelligence

superintelligence: "an intellect that is much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills."

- The program Fritz falls short of superintelligence even though it is much better than humans at chess, because Fritz cannot outperform humans in other tasks.
- Bostrom treats superintelligence as general dominance at goal-oriented behavior, leaving open whether an artificial or human superintelligence would possess capacities such as intentionality (cf. the Chinese room argument) or first-person consciousness (cf. the hard problem of consciousness).
    - The Chinese room is a thought experiment presented by the philosopher John Searle to challenge the claim that it is possible for a computer running a program to have a "mind" and "consciousness" in the same sense that people do, simply by virtue of running the right program.

strong AI:
    - "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."

His arguments

    - It argues that if machine brains surpass human brains in general intelligence, then this new superintelligence could replace humans as the dominant lifeform on Earth.
    - Sufficiently intelligent machines could improve their own capabilities faster than human computer scientists.
    - As the fate of gorillas now depends more on humans than on the actions of gorillas themselves, so will the fate of future humanity depend on the actions of the machine superintelligence.
    - The outcome could be an existential catastrophe for humans.

Downsides in his arguments

    - "The AI need not even have any malicious or megalomaniacal intent. It may just be trying to prove the Riemann hypothesis; but in single-minded pursuit of that goal, it will assemble all the resources, first on earth then in the galaxy, to build additional computational power for that purpose. Or it may have been instructed to make paperclips; in that case, it will turn the whole galaxy into paperclips. Do not think you can escape this doom by instructing it instead to make exactly one million paperclips. If it hears that, it will make the million paperclips, and then exhaust the resources of the universe checking and double checking that it counted correctly."
    - The assumption that intelligence is a potentially infinite quantity with a well defined, one-dimensional value.
        - Bostrom writes differential equations for intelligence, and characterizes their solutions. Certainly, if you asked Bostrom about this, he would say that this is a simplifying assumption made for the sake of making the analysis concrete. The problem is, that if you look at the argument carefully, it depends rather strongly on this idealization, and if you loosen the idealization, important parts of the argument become significantly weaker, such as Bostrom’s expectation that the progress from human intelligence to superhuman intelligence will occur quickly.
        - Bostrom claims that once you have a machine with the intelligence of a man, you can get a superintelligence just by making the thing faster and bigger. However, all that running faster does is to save you time. If you have two machines A and B and B runs ten times as fast as A, then A can do anything that B can do if you’re willing to wait ten times as long.
    - The assumption that a large gain in intelligence would necessarily entail a correspondingly large increase in power.
    - The assumption that large intelligence entails virtual omnipotence.
    - The unwarranted belief that, though achieving intelligence is more or less easy, giving a computer an ethical point of view is really hard.

### References:

- http://www.enotes.com/topics/big-test
